{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGRAMA DE CIENCIAS DE LOS DATOS \n",
    "# **Curso: Big Data**\n",
    "## **PROYECTO FINAL:**\n",
    "\n",
    "## <font color='red'>Machine Learning con datos en PostgreSQL</font>. \n",
    "\n",
    "\n",
    "#### **Profesor: MSc. Felipe Meza Obando**\n",
    "\n",
    "\n",
    "#### Alumnos: \n",
    "  \n",
    "####  **Lester Salazar Viales.**\n",
    "####  **Randal Salazar Viales.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo del Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se efectuará un Análisis de datos de Machine Learning, a una base de datos que se encuentra ubicada en una **BD PostgreSQL**.\n",
    "\n",
    "Para la BD a emplear, se efectuará un **análisis predictorio**, para tratar de **determinar la cantidad de días de vacaciones que  posee cada empleado**, de acuerdo a las features existentes en la BD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\spark')\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Basic JDBC pipeline\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"C:\\Spark\\jdbcdriver\\postgresql-42.2.9.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"C:\\Spark\\jdbcdriver\\postgresql-42.2.9.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión a BD PostgreSQL mediante Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del DataFrame de datos de BD empleada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dataframe de Tabla Empleados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+------------+---------+----------+------------+--------------------+-------------+----------------+------------+---------------+----------+----+\n",
      "|    Cedula|Apellido1|Apellido2|              Nombre|Cod_Planilla|Provincia|Cod_Canton|Cod_Distrito|           Direccion|Fecha_Ingreso|Fecha_Nacimiento|Fecha_Salida|Jornada_Trabajo|Cod_Puesto|Sexo|\n",
      "+----------+---------+---------+--------------------+------------+---------+----------+------------+--------------------+-------------+----------------+------------+---------------+----------+----+\n",
      "|0304810504|   ABARCA|  MIRANDA|       SUSANA ARIELA|           Q|        3|        02|         000|CARTAGO, PARAISO,...|   2017-05-03|      1994-09-14|        null|              A|   ASB2.33|   F|\n",
      "|0304340108|   ABARCA|    ARAYA|YENIFFER DE LOS A...|           Q|        3|        08|         010|RESIDENCIAL LOS Z...|   2007-12-03|      1989-01-25|        null|              A|   ASB2.33|   F|\n",
      "|0112970847|   ABARCA|    ARIAS|         OLMAN JESUS|           Q|        1|        18|         020|GRANADILLA NORTE,...|   2019-06-20|      1986-11-11|        null|              A|   PRO8.25|   M|\n",
      "|0114020196|   ABARCA|   CAMPOS|      EMILIO ESTEBAN|           Q|        1|        18|         000|CURRIDABAT, LOMAS...|   2006-12-01|      1984-08-24|        null|              A|   PRO7.32|  M7|\n",
      "|0107290438|   ABARCA| GUERRERO| LUIS ESTEBAN MARTIN|           Q|        1|        03|         070|DIAGONAL AL CEMEN...|   1987-04-20|      1968-09-13|        null|              A|  HASB3.07|   M|\n",
      "+----------+---------+---------+--------------------+------------+---------+----------+------------+--------------------+-------------+----------------+------------+---------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "empleados_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost/rhdb\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"bd2019%\") \\\n",
    "    .option(\"dbtable\", \"empleados\") \\\n",
    "    .load()\n",
    "\n",
    "empleados_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del esquema del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Apellido1: string (nullable = true)\n",
      " |-- Apellido2: string (nullable = true)\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- Cod_Planilla: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Cod_Canton: string (nullable = true)\n",
      " |-- Cod_Distrito: string (nullable = true)\n",
      " |-- Direccion: string (nullable = true)\n",
      " |-- Fecha_Ingreso: date (nullable = true)\n",
      " |-- Fecha_Nacimiento: date (nullable = true)\n",
      " |-- Fecha_Salida: date (nullable = true)\n",
      " |-- Jornada_Trabajo: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empleados_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dataframe de Tabla Vacaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-------------+--------------------+---------------+---------------+\n",
      "|    Cedula|Periodo_vacaciones|Fecha_Derecho|        Dias_Derecho|Dias_Disfrutado|Dias_Adelantado|\n",
      "+----------+------------------+-------------+--------------------+---------------+---------------+\n",
      "|0118020085|              2020|   2019-05-22|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0110160466|              2020|   2001-07-20|30.00000000000000...|          0E-18|          0E-18|\n",
      "|0116260447|              2020|   2018-11-23|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0115470697|              2020|   2017-12-01|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0304350400|              2020|   2016-05-02|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0304810504|              2020|   2017-05-03|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0117110780|              2020|   2016-12-26|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0305150108|              2020|   2018-08-09|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0115620398|              2020|   2016-06-13|15.00000000000000...|          0E-18|          0E-18|\n",
      "|0117670109|              2020|   2019-02-26|15.00000000000000...|          0E-18|          0E-18|\n",
      "+----------+------------------+-------------+--------------------+---------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "emp_vacac_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost/rhdb\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"bd2019%\") \\\n",
    "    .option(\"dbtable\", \"empleado_vacaciones\") \\\n",
    "    .load()\n",
    "\n",
    "emp_vacac_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del esquema del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Periodo_vacaciones: string (nullable = true)\n",
      " |-- Fecha_Derecho: date (nullable = true)\n",
      " |-- Dias_Derecho: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Disfrutado: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Adelantado: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_vacac_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dataframe de Tabla Empleado-Ingreso-Egreso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+----------------+---------------------+-------------------+--------------------+------------------------+----------+----------+---------+--------+\n",
      "|    Cedula|Cod_Concepto_Salarial|Fecha_Rige_Desde|Estado_Ingreso_Egreso|Tipo_Ingreso_Egreso|       Monto_Aplicar|Categoria_Ingreso_Egreso|Forma_Pago|Cod_Puesto|Cod_Plaza|Cod_Area|\n",
      "+----------+---------------------+----------------+---------------------+-------------------+--------------------+------------------------+----------+----------+---------+--------+\n",
      "|0118020085|                  041|      2018-01-01|                    A|                  I|257627.2000000000...|                     SAL|         C|   ASB2.33|     3227|     051|\n",
      "|0110160466|                  001|      2018-01-01|                    A|                  I|441407.0400000000...|                     SAL|         C|   PRC8.03|     2847|     051|\n",
      "|0116260447|                  041|      2018-01-01|                    A|                  I|309285.9200000000...|                     SAL|         C|   ASB2.33|     4008|     051|\n",
      "|0115470697|                  041|      2018-01-01|                    A|                  I|309285.9200000000...|                     SAL|         C|   ASB2.33|     4218|     051|\n",
      "|0304350400|                  041|      2018-01-01|                    A|                  I|309285.9200000000...|                     SAL|         C|   ASB2.33|     4233|     051|\n",
      "+----------+---------------------+----------------+---------------------+-------------------+--------------------+------------------------+----------+----------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "emp_ingr_egre_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost/rhdb\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"bd2019%\") \\\n",
    "    .option(\"dbtable\", \"empleado_ingreso_egreso\") \\\n",
    "    .load()\n",
    "\n",
    "emp_ingr_egre_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del esquema del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Cod_Concepto_Salarial: string (nullable = true)\n",
      " |-- Fecha_Rige_Desde: date (nullable = true)\n",
      " |-- Estado_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Tipo_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Monto_Aplicar: decimal(38,18) (nullable = true)\n",
      " |-- Categoria_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Forma_Pago: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Cod_Plaza: string (nullable = true)\n",
      " |-- Cod_Area: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_ingr_egre_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Unión de los 3 dataframes para tener todas las columnas necesarias pra efectuar el Análisis en un solo dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unión de dataframes: **empleados_df + emp_vacac_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "join12 = empleados_df.join(emp_vacac_df, empleados_df.Cedula == emp_vacac_df.Cedula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Apellido1: string (nullable = true)\n",
      " |-- Apellido2: string (nullable = true)\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- Cod_Planilla: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Cod_Canton: string (nullable = true)\n",
      " |-- Cod_Distrito: string (nullable = true)\n",
      " |-- Direccion: string (nullable = true)\n",
      " |-- Fecha_Ingreso: date (nullable = true)\n",
      " |-- Fecha_Nacimiento: date (nullable = true)\n",
      " |-- Fecha_Salida: date (nullable = true)\n",
      " |-- Jornada_Trabajo: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Periodo_vacaciones: string (nullable = true)\n",
      " |-- Fecha_Derecho: date (nullable = true)\n",
      " |-- Dias_Derecho: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Disfrutado: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Adelantado: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join12.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparación de valores de campo Cédula de ambos dataframes anteriores en el nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|    Cedula|    Cedula|\n",
      "+----------+----------+\n",
      "|0110530432|0110530432|\n",
      "|0111710991|0111710991|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join12.select(empleados_df['Cedula'], emp_vacac_df['Cedula']).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminación de columnas demás del dataframe nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data12 = join12.select([empleados_df['Cedula'], 'Cod_Planilla', 'Provincia','Fecha_Ingreso', 'Fecha_Nacimiento', \n",
    "                        'Jornada_Trabajo', 'Cod_Puesto', 'Sexo', 'Dias_Derecho', 'Dias_Disfrutado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+\n",
      "|    Cedula|Cod_Planilla|Provincia|Fecha_Ingreso|Fecha_Nacimiento|Jornada_Trabajo|Cod_Puesto|Sexo|        Dias_Derecho|Dias_Disfrutado|\n",
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+\n",
      "|0110530432|           Q|        3|   2005-11-21|      1979-01-05|              A|  HPRC8.10|   F|20.00000000000000...|          0E-18|\n",
      "|0111710991|           Q|        6|   2006-10-02|      1983-05-14|              A|   PRC4.11|   M|20.00000000000000...|          0E-18|\n",
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data12.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Cod_Planilla: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Fecha_Ingreso: date (nullable = true)\n",
      " |-- Fecha_Nacimiento: date (nullable = true)\n",
      " |-- Jornada_Trabajo: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- Dias_Derecho: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Disfrutado: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data12.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unión de dataframes: **join12_df + emp_ingr_egre_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "join23 = data12.join(emp_ingr_egre_df, data12.Cedula == emp_ingr_egre_df.Cedula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Cod_Planilla: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Fecha_Ingreso: date (nullable = true)\n",
      " |-- Fecha_Nacimiento: date (nullable = true)\n",
      " |-- Jornada_Trabajo: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- Dias_Derecho: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Disfrutado: decimal(38,18) (nullable = true)\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Cod_Concepto_Salarial: string (nullable = true)\n",
      " |-- Fecha_Rige_Desde: date (nullable = true)\n",
      " |-- Estado_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Tipo_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Monto_Aplicar: decimal(38,18) (nullable = true)\n",
      " |-- Categoria_Ingreso_Egreso: string (nullable = true)\n",
      " |-- Forma_Pago: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Cod_Plaza: string (nullable = true)\n",
      " |-- Cod_Area: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join23.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparación de valores de campo Cédula de ambos dataframes anteriores en el nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|    Cedula|    Cedula|\n",
      "+----------+----------+\n",
      "|0110530432|0110530432|\n",
      "|0111710991|0111710991|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join23.select(data12['Cedula'], emp_ingr_egre_df['Cedula']).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminación de columnas demás del dataframe nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = join23.select([data12['Cedula'], 'Cod_Planilla', 'Provincia','Fecha_Ingreso', 'Fecha_Nacimiento', 'Jornada_Trabajo', \n",
    "                         data12['Cod_Puesto'], 'Sexo', 'Dias_Derecho', 'Dias_Disfrutado', 'Cod_Concepto_Salarial', \n",
    "                         'Monto_Aplicar', 'Cod_Area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataframe con columnas a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cedula: string (nullable = true)\n",
      " |-- Cod_Planilla: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- Fecha_Ingreso: date (nullable = true)\n",
      " |-- Fecha_Nacimiento: date (nullable = true)\n",
      " |-- Jornada_Trabajo: string (nullable = true)\n",
      " |-- Cod_Puesto: string (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- Dias_Derecho: decimal(38,18) (nullable = true)\n",
      " |-- Dias_Disfrutado: decimal(38,18) (nullable = true)\n",
      " |-- Cod_Concepto_Salarial: string (nullable = true)\n",
      " |-- Monto_Aplicar: decimal(38,18) (nullable = true)\n",
      " |-- Cod_Area: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+---------------------+--------------------+--------+\n",
      "|    Cedula|Cod_Planilla|Provincia|Fecha_Ingreso|Fecha_Nacimiento|Jornada_Trabajo|Cod_Puesto|Sexo|        Dias_Derecho|Dias_Disfrutado|Cod_Concepto_Salarial|       Monto_Aplicar|Cod_Area|\n",
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+---------------------+--------------------+--------+\n",
      "|0110530432|           Q|        3|   2005-11-21|      1979-01-05|              A|  HPRC8.10|   F|20.00000000000000...|          0E-18|                  041|855421.4700000000...|     001|\n",
      "|0111710991|           Q|        6|   2006-10-02|      1983-05-14|              A|   PRC4.11|   M|20.00000000000000...|          0E-18|                  041|464802.1700000000...|     051|\n",
      "+----------+------------+---------+-------------+----------------+---------------+----------+----+--------------------+---------------+---------------------+--------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cálculo de cantidad de días de vacaciones disponibles de cada empleado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cálculo de días de vacaciones viene en función de las columnas **Dias_Derecho** y **Dias_Disfrutado**.\n",
    "\n",
    "Se calcula de la siguiente forma:\n",
    "\n",
    "    Si Dias_Disfrutado < 0, Vacaciones = Dias_Disfutado, de lo contrario\n",
    "                            Vacaciones = (Dias_Derecho - Dias_Disfrutado\n",
    "\n",
    "Por tanto, si Vacaciones < 0, la persona a realizado más días de vacaciones de las que tiene disponible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
