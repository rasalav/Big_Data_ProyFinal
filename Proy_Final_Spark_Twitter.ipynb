{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGRAMA DE CIENCIAS DE LOS DATOS \n",
    "# **Curso: Big Data**\n",
    "## **PROYECTO FINAL:**\n",
    "\n",
    "## <font color='red'>Streaming de tendencias con #hashtags en Twitter</font>. \n",
    "## <font color='blue'>Parte 2: Procesamiento de DataStreaming en APACHE SPARK</font>. \n",
    "\n",
    "#### **Profesor: MSc. Felipe Meza Obando**\n",
    "\n",
    "\n",
    "#### Alumnos: \n",
    "  \n",
    "####  **Lester Salazar Viales.**\n",
    "####  **Randal Salazar Viales.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta parte, es poder efectuar el procesamiento de los datos Streaming que son adquiridos del servidor tipo socket. Mediante una conexión tipo cliente, Spark logra obtener los datos de TWITTER del servidor tipo socket y efectuar el procesado correspondiente de los hashtags en tiempo real de ese momento.\n",
    "\n",
    "Como criterio de diseño, se escogió poder visualizar el top 10 de hashtags populares en el momento de la corrida (hashtags que más se repitieran en ese momento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Configuración de Apache Spark Streaming</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación de Librerías** a ser utilizadas para el Streaming de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librería PySpark\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "# Otras Librerias PySpark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql.functions import explode, split, size, from_json\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Librerías del Sistema Operativo\n",
    "import os\n",
    "\n",
    "# Librerías Numéricas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Librerías de Preprocesamiento de datos Twitter\n",
    "import preprocessor as p\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de FindSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "# Ruta de Apache Spark para sistema Mac/OS\n",
    "#findspark.init('/opt/spark')\n",
    "\n",
    "# Ruta de Apache Spark para sistema Windows/OS\n",
    "findspark.init('C:\\Spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, size\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TwitterSpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Schema de datos TWITTER a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La definición de datos del esquema a emplear, debe ser coincidente con los datos que se envían por streaming desde el servidor socket, de lo contrario, los datos serán almacenados erróneamente y el procesamiento no será lo requerido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir schema para el input data\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"created_at\", StringType()),\\\n",
    "                     StructField(\"text\", StringType()),\\\n",
    "                     StructField(\"userid\", StringType()),\\\n",
    "                     StructField(\"username\", StringType()),\\\n",
    "                     StructField(\"userlocation\", StringType()),\\\n",
    "                     StructField(\"retweet_count\", IntegerType()),\\\n",
    "                     StructField(\"entities\", ArrayType(StringType())),\\\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del StreamDataframe de datos TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe crear el streamdataframe  que almacena los datos de TWITTER, que son enviados desde el servidor tipo socket configurado anteriormente. Los datos de TWITTER recibidos, son acorde a lo requerido por el schema de datos escogido previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 5555).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización de si el dataframe definido anteriormente es un streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificación de si el DataFrame tiene datos Streaming o NO\n",
    "lines.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización del Schema  del streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Otra forma de visualización las columnas del streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[value: string]\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Creación de streamdatafrme que almacenará los datos de TWITTER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creación de este dataframe es en función del schema definido, y valiéndose de que los datos TWITTER son creados en archivos JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = lines.select(\n",
    "    from_json('value', schema).created_at.alias('created_at'),\n",
    "    from_json('value', schema).text.alias('text'),\n",
    "    from_json('value', schema).userid.alias('userid'),\n",
    "    from_json('value', schema).username.alias('username'),\n",
    "    from_json('value', schema).userlocation.alias('userlocation'),\n",
    "    from_json('value', schema).retweet_count.alias('retweet_count'),\n",
    "    from_json('value', schema).entities.alias('entities')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización del Schema  del streamdataframe de datos TWITTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userid: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- userlocation: string (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- entities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Ampliar el Array Entities para poder extraer el elemento \"Hashtag\" y almacenarlo en el streamdataframe de datos TWITTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_entities = df_twitter.withColumn('hashtag', explode(df_twitter.entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización de si el dataframe definido anteriormente es un streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificación de si el DataFrame tiene datos Streaming o NO\n",
    "exp_entities.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Otra forma de visualización las columnas del streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[created_at: string, text: string, userid: string, username: string, userlocation: string, retweet_count: int, entities: array<string>, hashtag: string]\n"
     ]
    }
   ],
   "source": [
    "print(exp_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Operación de agrupamiento de hashtags iguales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta operación, se agruparán todos los hashtags que son iguales, así mismo se agregarán dos columnas adicionales:\n",
    "\n",
    "- count(hashtag): almacenará la cantidad de hashtag que se repiten\n",
    "\n",
    "- sum(retweeet_count): almacena la suma de retweets de los hashtag que se repiten\n",
    "\n",
    "Luego de esto, se ordenarán los datos en orden descendente de acuerdo a la cantidad de hashtag repetidos (de mayor a menor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tweets = exp_entities.select('hashtag', 'retweet_count', 'userlocation', 'userid') \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .agg({'hashtag':'count', 'retweet_count':'sum'}) \\\n",
    "    .sort('count(hashtag)', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Creación del query para poder accesar a los datos del streamdataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=total_tweets.writeStream.queryName('query_hashtag').outputMode('complete').format('memory').start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Descripción del streamdataframe del query final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+-------+\n",
      "|          col_name|data_type|comment|\n",
      "+------------------+---------+-------+\n",
      "|           hashtag|   string|   null|\n",
      "|sum(retweet_count)|   bigint|   null|\n",
      "|    count(hashtag)|   bigint|   null|\n",
      "+------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Describe query_hashtag\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización de cantidad de datos procesados en el streamdataframe del query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from query_hashtag \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Actualización de cantidad de datos procesados en el streamdataframe del query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      68|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from query_hashtag \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización de los 5 primeros datos procesados de la columna hashtag del streamdataframe del query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|     hashtag|\n",
      "+------------+\n",
      "|SeraKutlubey|\n",
      "|CemreKaraçay|\n",
      "|      CenCem|\n",
      "| OzanDolunay|\n",
      "| CenkKaraçay|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select hashtag from query_hashtag \").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionar los 10 Hashtags más populares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionando el top 10 por Consulta SQL al StreamdataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Visualización del resultado como DataFrame de Pandas para el comando basico Spark SQL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>sum(retweet_count)</th>\n",
       "      <th>count(hashtag)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SeraKutlubey</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CemreKaraçay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CenCem</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OzanDolunay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CenkKaraçay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>بدايتِي</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>لي</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KUWTacha</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ReleaseSharjeelImmediately</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>이달의소녀</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      hashtag  sum(retweet_count)  count(hashtag)\n",
       "0                SeraKutlubey                   0              25\n",
       "1                CemreKaraçay                   0              25\n",
       "2                      CenCem                   0              25\n",
       "3                 OzanDolunay                   0              25\n",
       "4                 CenkKaraçay                   0              25\n",
       "5                     بدايتِي                   0              21\n",
       "6                          لي                   0              21\n",
       "7                    KUWTacha                   0               8\n",
       "8  ReleaseSharjeelImmediately                   0               8\n",
       "9                       이달의소녀                   0               6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"Select * from query_hashtag \").toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Otra manera de obtener el resultado como DataFrame de Pandas para el comando basico Spark SQL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>sum(retweet_count)</th>\n",
       "      <th>count(hashtag)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SeraKutlubey</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CemreKaraçay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CenCem</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OzanDolunay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CenkKaraçay</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>بدايتِي</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>لي</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KUWTacha</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ReleaseSharjeelImmediately</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>이달의소녀</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      hashtag  sum(retweet_count)  count(hashtag)\n",
       "0                SeraKutlubey                   0              25\n",
       "1                CemreKaraçay                   0              25\n",
       "2                      CenCem                   0              25\n",
       "3                 OzanDolunay                   0              25\n",
       "4                 CenkKaraçay                   0              25\n",
       "5                     بدايتِي                   0              21\n",
       "6                          لي                   0              21\n",
       "7                    KUWTacha                   0               8\n",
       "8  ReleaseSharjeelImmediately                   0               8\n",
       "9                       이달의소녀                   0               6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"Select * from query_hashtag desc limit 10\").toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualización de cantidad de datos procesados en el streamdataframe del query (para ver si se está actualizando con más datos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     370|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from query_hashtag \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Comando de espera por si se termina la comunicación  entre el servidor tipo socket y Apache Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
